The Density Matrix Renormalization Group (DMRG) algorithm, a variational method over the class of Matrix Product States (MPS), has developed to be the de-facto standard for the numerical simulation of one-dimensional quantum systems. The success of this method is due to the remarkable ability of MPS to capture the area law entanglement characteristics of ground states of gapped Hamiltonians. Additionally, due to the elegant diagrammatic notation of tensor networks, new algorithms can be developed and discussed efficiently and intuitively. Applications of MPS include finding ground and thermal states, real and imaginary time evolution, and the computation of dynamical properties of lattice Hamiltonians. In the following, we give a brief introduction to MPS, for a more in-depth discussion see \cite{cite:DMRG_in_the_age_of_MPS, cite:practical_introduction_MPS_and_PEPS, cite:tenpy}. \par
The state of a quantum many-body system can be written as
\begin{equation}
	\ket{\Psi} = \sum_{i_1=1}^{d_1} \sum_{i_2=1}^{d_2} \cdots \sum_{i_N=1}^{d_N} \Psi_{i_1,i_2,\dots,i_N} \ket{i_1} \otimes \ket{i_2} \otimes \cdots \otimes \ket{i_N},
\end{equation}
where $N$ is the number of subsystems (e.g. lattice sites or particles), and $\left\{\ket{i_1} \otimes \ket{i_2} \otimes \dots \otimes \ket{i_N}\right\}$, $i_j = 0, \dots, d_j$ is a set of basis vectors of the full many-body Hilbert space
\begin{equation}
	\mathcal{H} = \bigotimes_{j=1}^{N} \mathcal{H}_j,
\end{equation}
with $\dim\left(\mathcal{H}_j\right) = d_j$ the dimension of the local Hilbert space of subsystem $j$. To simplify the notation, we will assume that the dimension of all local subsystems is the same, $d_j = d$. The $d^N$ complex numbers $\Psi_{i_1,i_2,\dots,i_N}$ fully describe the quantum many-body state, and one can think of $\Psi\in\mathbb{C}^{d\times\cdots\times d}$ as a tensor of rank $N$. However, due to the number of parameters scaling exponentially with system size, only very small system sizes are accessible computationally. One can proceed by writing $\Psi$ as a tensor network of tensors of lower rank. A \textit{Matrix Product State} (MPS) is constructed by introducing $N$ rank-3 tensors $T^{[n]}\in\mathbb{C}^{d\times \chi_{n-1}\times \chi_{n}}$ and contracting them in a chain as
\begin{equation}
	\label{eq:MPS_open_boundary_conditions_general_definition}
	\Psi_{i_1,i_2,\cdots,i_N} \coloneqq \sum_{\alpha_1=1}^{\chi_1} \sum_{\alpha_2=1}^{\chi_2}\dots\sum_{\alpha_{N-1}=1}^{\chi_{N-1}}T^{[1],i_1}_{1,\alpha_1} T^{[2],i_2}_{\alpha_1,\alpha_2} \cdots T^{[N],i_N}_{\alpha_{N-1},1},
\end{equation}
where we have written the indices $i_n$ as superscripts, such that the sums are performed only over subscripts. Note that in this notation the bond dimensions at the two ends of the chain are $\chi_0 = \chi_{N} = 1$, and we can interpret the tensors $T^{[1]}$ and $T^{[N]}$ as tensors of rank-2. Since the indices $i_n = 0, 1, \dots d$ represent the local physical degrees of freedom, they are sometimes referred to as \textit{physical indices}. The other indices are called \textit{virtual indices}. A tensor diagram of the MPS \eqref{eq:MPS_open_boundary_conditions_general_definition} is given in Figure \figref{fig:mps_general}.\par
\begin{figure}
	\centering
	\includegraphics[scale=1]{figures/tikz/Tensor_Networks/mps_basic/mps_basic.pdf}
	\caption{Diagrammatic representation of the Matrix Product State \eqref{eq:MPS_open_boundary_conditions_general_definition}.}
	\label{fig:mps_general}
\end{figure}
\begin{figure}
\centering
\includegraphics[scale=1]{figures/tikz/Tensor_Networks/mps_local_expectation_value/mps_local_expectation_value.pdf}
\caption{The computation of the expectation value of a local operator can be computed by contracting the MPS with its conjugate transpose, with the operator "sandwiched" in between.}
\label{fig:mps_local_expectation_value}
\end{figure}
An important property of MPS is the existence of a \textit{canonical form} as an isometric tensor network, where a single tensor $T^{[n]} \eqqcolon \Lambda^{[n]}$ is selected as the orthogonality center. One can bring an arbitrary MPS into this canonical form through successive QR-decompositions or SVDs, starting at the outer ends of the chain and isometrizing one tensor at a time, until the orthogonality center is reached \cite{cite:DMRG_in_the_age_of_MPS}. In Figure \figref{fig:mps_canonical_form_general_definition} an MPS in canonical form with the orthogonality center at subsystem $n$ is visualized in diagrammatic notation. We call tensors to the left of the orthogonality center $A^{[i]}$ and tensors to the right of the orthogonality center $B^{[i]}$. The canonical form greatly simplifies many operations on MPS and allows for the formulation of efficient algorithms, where many contractions reduce to identity due to the isometry condition \eqref{eq:isometry_condition_general}, see Figure \figref{fig:mps_left_isometry_condition} and Figure \figref{fig:mps_right_isometry_condition}. For example, the expectation value $\bra{\Psi}\hat{O}\ket{\Psi}$ of a one-site operator $\hat{O} \in \mathbb{C}^{d\times d}$ acting on site $n$ can for a general MPS be computed as
\begin{equation}
\begin{split}
	\label{eq:computation_of_expectation_value_MPS}
	\bra{\Psi}\hat{O}\ket{\Psi} &=\sum_{i_1,\dots,i_N,j_n=1}^{d}\Psi_{i_1,i_2,\dots,i_N} \Psi_{i_1,\dots,i_{n-1},j_n,i_{n+1},\dots,i_N}^* \bra{j_n}\hat{O} \ket{i_n} \\
	&= \sum_{i_1,\dots,i_N,j_n=1}^{d} \left(T^{[1],i_1}\cdots T^{[N],i_N}\right) \\
	&\quad\quad\quad\quad\quad\,\,\cdot\left(T^{[1],i_1*}\cdots T^{[n],j_n*} \cdots T^{[N],i_N*}\right)\cdot \hat{O}_{i_n,j_n},
\end{split}
\end{equation}
where the $T^{[n],i_n}$ are interpreted as matrices for $1 < n < N$ and as row/column vectors for $n = 1, N$ such that the product
\begin{equation}
	\left(T^{[1],i_1}\cdots T^{[N],i_N}\right)
\end{equation}
gives a scalar. The contraction \eqref{eq:computation_of_expectation_value_MPS} is visualized as a tensor diagram in Figure \figref{fig:mps_local_expectation_value}. Here the advantage of the diagrammatic notation becomes appearant: It is much easier to understand how tensors are contracted when expressing the contraction in terms of tensor network diagrams. The computational cost of computing the expectation value scales linear with the system size $\mathcal{O}\left(N\chi^3d\right)$, where $\chi$ is the maximum virtual bond dimension $\chi = \max\left\{\chi_1,\dots,\chi_N\right\}$. If the MPS is however given in canonical form with the orthogonality center at site $n$, the computation reduces to a contraction of only three tensors as can be seen in Figure \figref{fig:mps_local_expectation_value_canonical}, and the computational cost $\mathcal{O}\left(\chi^3d\right)$ becomes independent of system size. \par
\begin{figure}
	\centering
	\begin{minipage}{1.0\textwidth}
		\centering
		\subcaptionbox{\label{fig:mps_canonical_form_general_definition}}
		{%
			\includegraphics[scale=1]{figures/tikz/Tensor_Networks/mps_canonical_form/mps_canonical_form_a.pdf}
		}
	\end{minipage}
	\par\medskip
	\centering
	\subcaptionbox{\label{fig:mps_left_isometry_condition}}
	{%
		\includegraphics[scale=1]{figures/tikz/Tensor_Networks/mps_canonical_form/mps_canonical_form_b.pdf}
	}
	\quad\quad\quad\quad\quad
	\subcaptionbox{\label{fig:mps_right_isometry_condition}}
	{%
		\includegraphics[scale=1]{figures/tikz/Tensor_Networks/mps_canonical_form/mps_canonical_form_c.pdf}
	}
	\caption{(a) Diagrammatic representation of an MPS in canonical form. (b) The left isometry condition. (c) The right isometry condition.}
	\label{fig:mps_canonical}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[scale=1.0]{figures/tikz/Tensor_Networks/mps_canonical_form_local_expectation_value/mps_canonical_form_local_expectation_value.pdf}
	\caption{If the MPS is in canonical form, the computation of the expectation value of a local operator can be simplified to a contraction of only three tensors using the isometry condition.}
	\label{fig:mps_local_expectation_value_canonical}
\end{figure}
\subsubsection*{\hspace{95pt}Approximating Quantum States with MPS}
Until now, the MPS representation of $\ket{\Psi}$ is still exact. One can approximate an MPS by restricting the virtual bond dimension to a maximal bond dimension $\chi_n \le \chi_\text{max}$. In this case, the number of parameters that need to be stored to describe the state is reduced from $\mathcal{O}\left(d^N\right)$ to $\mathcal{O}\left(N\chi_\text{max}^2 d\right)$. To arrive at this approximation, two neighboring tensors can be contracted and split via a truncated SVD, keeping only the $\chi_\text{max}$ largest singular values. If the orthogonality center of the MPS is at one of the two tensors, this approximation is globally optimal as explained in Section \ref{sec:tensors_and_tensor_networks_isometric_tensor_networks}. Additionally, this SVD at the orthogonality center is related to the Schmidt decomposition of a bipartite system
\begin{equation}
	\ket{\Psi} = \sum_{\alpha=1}^{\chi_n} \lambda_\alpha \ket{\Psi^{[L]}_\alpha} \otimes \ket{\Psi^{[R]}_\alpha},
\end{equation}
where the chain is split into a left and right subsystem, grouping all indices to the left and right of the orthogonality center into orthogonal basis vectors $\ket{\Psi^{[L]}_\alpha}$ and $\ket{\Psi^{[R]}_\alpha}$ respectively. In this case, the Schmidt values $\lambda_\alpha \ge 0$ coincide with the singular values \cite{cite:DMRG_in_the_age_of_MPS} and one can compute the Von-Neumann entanglement entropy
\begin{equation}
	S = -\sum_{\alpha=1}^{\chi_n} \lambda_\alpha^2 \log\left(\lambda_\alpha^2\right),
\end{equation}
quantifying the amount of entanglement between the left and right subsystem. If the state is normalized, it additionally holds
\begin{equation}
	\sum_{\alpha=1}^{\chi_n} \lambda_\alpha^2 = 1.
\end{equation}
Thus, how well an MPS of a given bond dimension $\chi_\text{max}$ is able to represent a given quantum state is highly dependent on the Schmidt spectrum $\left\{\lambda_\alpha\right\}$ at the different bipartitions of the chain. If the Schmidt values decrease exponentially, only an exponentially small part of the entanglement structure is truncated and the MPS is a good approximation for the original state. It can be shown \cite{cite:area_law_1D_proof, cite:area_laws_review} that for ground states of local, gapped, one dimensional Hamiltonians there holds an \textit{area law}: The entanglement entropy at arbitrary bipartitions of the chain is bounded by a constant
\begin{equation}
	S \le S_\text{max}, 
\end{equation}
where $S_\text{max}$ is independent of the system size. This is in contrast to the fact that the entanglement of states drawn randomly from the many-body Hilbert space on average exhibits \textit{volume law} scaling
\begin{equation}
	\mathbb{E}\left[S\right] > \min\left(N_L, N_R\right)\log(d),
\end{equation}
where $N_L$ and $N_R$ are the number of subsystems in the left and right bipartition. Hence, ground states of gapped Hamiltonians are very non-generic. Note that the constant $S_\text{max}$ scales with the correlation length of the system, which diverges when approaching critical points. \par
It is immediately clear that truncated MPS by construction exhibit area law entanglement scaling if the local subsystems that are represented by each tensor correspond to physical systems on a 1D chain. The maximal entanglement entropy for a bipartition can be reached when all Schmidt values are equal, i.e. $\lambda_\alpha = 1/\sqrt{\chi_n}$ for $\alpha = 1,\dots\chi_n$, and thus
\begin{equation}
	S \le \log\left(\chi_\text{max}\right)
\end{equation}
for arbitrary bipartitions of the chain. One can conclude that MPS are good approximations for ground states of gapped 1D Hamiltonians away from criticality. \par 
For completeness we note that the truncation of all bonds of an MPS is a highly non-linear optimization problem and the naive algorithm of truncating each bond with an SVD does in general not lead to a minimal error. A variational compression procedure can be used to obtain a lower error at the same maximum bond dimension $\chi_\text{max}$ \cite{cite:DMRG_in_the_age_of_MPS}. \par
\subsubsection*{\hspace{162pt}Time Evolution}
Many algorithms have been formulated in the language of MPS. Most notably, the Density Matrix Renormalization Group (DMRG) algorithm can be used for finding ground states of local lattice Hamiltonians \cite{cite:DMRG_in_the_age_of_MPS}. Time evolution of MPS can for example be performed with the Time Evolving Block Decimation (TEBD) algorithm \cite{cite:efficient_simulation_of_1D_quantum_many_body_systems, cite:matrix_product_density_operators_simulation_of_finite_temperature_and_dissipative_systems} or the Time Dependant Variational Principle (TDVP) \cite{cite:time_dependent_variational_principle_for_quantum_lattices, cite:unifying_time_evolution_and_optimization_with_MPS}. In the following, we will briefly discuss TEBD, as this algorithm can be generalized easily to isometric tensor product states of higher dimensions, which we will discuss in Section \ref{sec:YB_isoTPS_TEBD}. \par
Assume that we are given a quantum state $\ket{\Psi}$ in the form of an MPS and a Hamiltonian $\hat{H}$ that can be written as a sum of nearest-neighbor operators $\hat{h}^{[j,j+1]}$,
\begin{equation}
	\hat{H} = \sum_{j = 1}^{N-1} \hat{h}^{[j,j+1]}.
\end{equation}
According to the Schrödinger equation, the state $\ket{\Psi}$ can be evolved in time as
\begin{equation}
	\ket{\Psi(t)} = \hat{U}\left(t\right) \ket{\Psi} = e^{-it\hat{H}} \ket{\Psi},
\end{equation}
where we have set $\hbar = 1$. The time evolution operator $\hat{U}(t)$ is in general very hard to compute and handle exactly. Thus, $\hat{U}(t)$ is approximated using a \textit{Suzuki-Trotter decomposition}. We start by decomposing the time evolution into a series of $K$ small time steps $\Delta t = t/K$ as
\begin{equation}
	\hat{U}(t) = e^{-it\hat{H}} = \left(e^{-i\Delta t\hat{H}}\right)^K = \left(\hat{U}(\Delta t)\right)^K.
\end{equation}
Next, we split the Hamiltonian into terms acting on even and odd bonds
\begin{equation}
	\hat{H} = \sum_{j \text{ even}}\hat{h}^{[j, j+1]} + \sum_{j \text{ odd}}\hat{h}^{[j, j+1]} \eqqcolon \hat{H}_\text{even} + \hat{H}_\text{odd}.
\end{equation}
We can then use the \textit{Zassenhaus formula}
\begin{equation}
	e^{\varepsilon(\hat{A}+\hat{B})} = e^{\varepsilon \hat{A}} e^{\varepsilon \hat{B}} e^{-\frac{\varepsilon^2}{2}[\hat{A}, \hat{B}]} e^{\frac{\varepsilon^3}{6}\left(2[\hat{B},[\hat{A},\hat{B}]]+[\hat{A},[\hat{A},\hat{B}]]\right)} \dots
\end{equation}
which can be derived from the Baker-Campbell-Hausdorff formula, to approximate
\begin{equation}
	\label{eq:mps_first_order_tebd}
	\begin{split}
		\hat{U}(\Delta t) &= e^{-i\Delta t\left(\hat{H}_\text{even} + \hat{H}_\text{odd}\right)} = e^{-i\Delta t\hat{H}_\text{even}}e^{-i\Delta t\hat{H}_\text{odd}} + \mathcal{O}\left(\Delta t^2\right) \\
		&= \hat{U}^\text{TEBD1}(\Delta t) + \mathcal{O}\left(\Delta t^2\right).
	\end{split}
\end{equation}
\begin{figure}
	\centering
	\subcaptionbox{\label{fig:mps_tebd_first_order_overview}}
	{%
		\includegraphics[scale=1]{figures/tikz/Tensor_Networks/mps_TEBD/mps_TEBD_a.pdf}
	}
	\par\medskip
	\subcaptionbox{\label{fig:mps_tebd_first_order_applying_bond_op}}
	{%
		\includegraphics[scale=1]{figures/tikz/Tensor_Networks/mps_TEBD/mps_TEBD_b.pdf}
	}
	\caption{(a) An MPS can be approximately evolved by a time $\Delta t$ by applying the first order TEBD operator \eqref{eq:mps_first_order_tebd}, which is made up of bond operators acting first on all even and then on all odd bonds. (b) To apply a single bond operator $\hat{U}^{[j, j+1]}$, the two corresponding tensors $\Lambda^{[j]}$ and $B^{[j+1]}$ are contracted with the operator into a tensor $\theta^{[j,j+1]}$, which is then split using truncated SVD to obtain the updated tensors $A^{[j]}$ and $\Lambda^{[j+1]}$.}
	\label{fig:mps_tebd_first_order}
\end{figure}
This is called a Suzuki-Trotter decomposition of first order. Since operators acting on even bonds commute with each other, the exponential $e^{-i\Delta t\hat{H}_\text{even}}$ factorizes,
\begin{equation}
	e^{-i\Delta t\hat{H}_\text{even}} = e^{-i\Delta t\sum_{j \text{ even}} \hat{h}^{[j, j+1]}} = \prod_{j \text{ even}} e^{-i\Delta t \hat{h}^{[j, j+1]}},
\end{equation}
and the same holds for the exponential $e^{-i\Delta t\hat{H}_\text{odd}}$. Each bond operator $\hat{U}^{[j, j+1]} \coloneqq e^{-i\Delta t \hat{h}^{[j, j+1]}}$ acting on the combined Hilbert space of sites $j$ and $j+1$ can be reshaped into a tensor of rank 4. The application of the operator $\hat{U}^\text{TEBD1}(\Delta t)$ to a state in MPS form can then be written as the tensor network in Figure \figref{fig:mps_tebd_first_order_overview}.
To perform a single TEBD iteration corresponding to a time evolution of $\Delta t$, we want to approximate this tensor network by a new MPS. This can be done by moving the orthogonality center from left to right, applying the bond operators $\hat{U}^{[j, j+1]}$ while keeping the MPS structure. The process of applying a single bond operator is shown in Figure \figref{fig:mps_tebd_first_order_applying_bond_op}. First, the orthogonality center is moved to site $j$. The two site tensors $\Lambda^{[j]}$ and $B^{[j+1]}$ are then contracted with the bond operator $\hat{U}^{[j, j+1]}$ into a single tensor $\theta$, which is subsequently split and truncated using an SVD. By sweeping twice across the MPS, first applying the bond operators on all even bonds and then the bond operators on all odd bonds, we perform a full TEBD iteration. There exist two sources of errors, the truncation error of the truncated SVD and the error of the Suzuki-Trotter decomposition. The truncation error can be controlled by choosing a larger bond dimension $\chi$, allowing the representation of more entanglement and thus the evolution to larger times. However, generally the amount of entanglement grows exponentially in time \cite{cite:DMRG_in_the_age_of_MPS}, necessitating an exponentially growing bond dimension and practically limiting the algorithm to small times. A smaller Suzuki-Trotter error can be achieved by choosing smaller time steps $\Delta t$ or by performing a higher-order Suzuki-Trotter decomposition. For example, a second order decomposition can be computed by symmetrizing two first-order decompositions of time step $\Delta t /2$ as
\begin{equation}
	\begin{split}
		\hat{U}(\Delta t) &= e^{-i\Delta t\left(\hat{H}_\text{even} + \hat{H}_\text{odd}\right)} = e^{-i\frac{\Delta t}{2}\hat{H}_\text{even}} e^{-i\Delta t \hat{H}_\text{odd}} e^{-i\frac{\Delta t}{2}\hat{H}_\text{even}} + \mathcal{O}\left(\Delta t^3\right)\\
		&= \hat{U}^\text{TEBD2}(\Delta t) + \mathcal{O}\left(\Delta t^3\right).
	\end{split}
\end{equation}
and can be applied to an MPS similarly as the first order decomposition. For higher order Suzuki-Trotter decompositions see \cite{cite:finding_exponential_product_formulas_of_higher_orders}.