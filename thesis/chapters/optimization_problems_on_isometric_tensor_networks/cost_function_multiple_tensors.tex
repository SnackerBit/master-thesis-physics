cost functions of multiple tensors $T_1, \dots T_K$ can be optimized iteratively via an algorithm similar to the Evenbly-Vidal algorithm. The idea is to optimize one tensor at a time, keeping all other tensors fixed. To optimize the tensor $T_i$, we again contract all other tensors into an environment tensor $E$. If the environment tensor is independent of $T_i$ (i.e. if the cost function is linear in $T_i$), we can update the tensor with the closed form solutions of Section \ref{sec:orthogonal_procrustes_problem}. Such an update is locally optimal in the sense that it maximizes $f(T_1, \dots, T_K)$ for fixed tensors $T_j$, $j\neq i$. If the environment tensor is dependant of $T_i$, we need to use the Evenbly-Vidal algorithm (see Section \ref{sec:evenbly_vidal_algorithm}) or Riemannian optimization (see Appendix \ref{app:riemannian_optimization_of_isometries}). If the cost function is linear in all tensors $T_1, \dots, T_K$ and bounded $f(T_1, \dots, T_K) \le c\in\mathbb{R}$, this algorithm is guaranteed to converge, since each local update is optimal and thus the cost function can never decrease. \par
An alternative approach for optimizing a cost function of multiple tensors is given by Riemannian optimization over product manifolds \cite{cite:riemannian_optimization_isometric_tensor_networks}.